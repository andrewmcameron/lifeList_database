---
title: "Constructing a Database from eBird Life List"
author: "Andrew Cameron"
date: "2023-05-12"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Databse structure

```{DBML, eval=false}

REATE TABLE "species" (
  "species_id" integer PRIMARY KEY,
  "common_name" varcahr,
  "banding_code" varchar,
  "scientific_name" varchar,
  "family" varchar,
  "conservation_status" varchar,
  "obs_id" integer
);

CREATE TABLE "observations" (
  "obs_id" integer PRIMARY KEY,
  "common_name" varcahr,
  "date" date,
  "loc_id" varchar,
  "checklist_id" varchar
);

CREATE TABLE "locations" (
  "loc_id" varchar PRIMARY KEY,
  "name" varchar,
  "lat" double,
  "long" double,
  "biome" varchar,
  "ecoregion" varchar
);

CREATE TABLE "checklists" (
  "checklist_id" varchar PRIMARY KEY,
  "duration" integer,
  "num_species" integer,
  "date" date,
  "temperature" float,
  "wind" float,
  "precipitation" float,
  "cloudcover" float,
  "loc_id" varchar
);

ALTER TABLE "observations" ADD FOREIGN KEY ("obs_id") REFERENCES "species" ("obs_id");

ALTER TABLE "locations" ADD FOREIGN KEY ("loc_id") REFERENCES "observations" ("loc_id");

ALTER TABLE "checklists" ADD FOREIGN KEY ("checklist_id") REFERENCES "observations" ("checklist_id");

ALTER TABLE "locations" ADD FOREIGN KEY ("loc_id") REFERENCES "checklists" ("loc_id");

```


```{r}
library(dplyr)
library(rebird)

lifelist <- readr::read_csv("lifelist.csv")

# Exclude non-species-level records and exotics/escapes
lifelist <- lifelist %>%
  slice(-(867:nrow(lifelist))) %>%
  mutate(`Row #` = row_number())

# Set ObservationID field
lifelist <- lifelist %>%
  mutate(ObsID = sort(`Row #`, decreasing = TRUE))

# Ensure all NN Park obs have same LocID
lifelist[lifelist$Location == "Newport News Park", "LocID"] <- "L718631"
                              
```

## Derive X,Y Coords for Locations

Lat/long data will be stored in 'Location Table' of database

Start with low hanging fruit: official hotspots.
```{r `FUNC hotspot coord`}

## ---- Custom func to return single-row df with x and y coords based on hotspot LocID
hotspot_xy <- function(hotspot_id) {
  
  info <- tryCatch(ebirdregioninfo(hotspot_id), 
                   error = function(e) {
    NULL  # If error, just return NULL
  })

  # Check if info is NULL
  if (is.null(info)) {
    # Return df with NAs if there was an error
    return(data.frame(LocID = hotspot_id,
                      lat = NA,
                      long = NA))
  } else {
    # Extract coordinates and return them if no error occurred
    y_coord <- info$latitude
    x_coord <- info$longitude
    return(data.frame(LocID = hotspot_id,
                      lat = y_coord,
                      long = x_coord))
  }
}


## ----- Apply custom func to get xy data from official hotspots
# df to hold location ID and resultant xy data
locations <- as.data.frame(unique(lifelist$LocID))
colnames(locations)[1] <- "LocID"


for (i in 1:nrow(locations)) {
  coords <- hotspot_xy(locations$LocID[i])
  
  locations$lat[i] <- coords$lat
  locations$long[i] <- coords$long
}

```

Many observations are not tied to recognized hotspots and thus require a bit more leg work to access their location data

* Some Loc names have xy data in the name -- use regex and stringr to extract those late/long strings

```{r `get missing coords`}
library(stringr)

# Subset locations that still lack spatial data
loc_noCoords <- locations %>%
  filter(is.na(lat)) %>%
  left_join(lifelist %>%
              group_by(LocID) %>%
              slice_head() %>%
              select(Location, LocID), by = "LocID")

#  Define regex pattern to identify lat and long strings
pattern <- "-?\\d+\\.\\d+,\\s*-?\\d+\\.\\d+"

loc_noCoords$extractedCoords <- str_extract(loc_noCoords$Location, pattern)

# Split string so lat and long are separated; this creates list object
coords_split <- str_split(loc_noCoords$extractedCoords, ",")

for (i in 1:nrow(loc_noCoords)) {
  if (!is.na(coords_split[[i]][1])) {
    loc_noCoords$lat[i] <- as.numeric(coords_split[[i]][1])
    loc_noCoords$long[i] <- as.numeric(coords_split[[i]][2])
  } else {
    loc_noCoords$lat[i] <- NA
    loc_noCoords$long[i] <- NA
  }
}


## ---- 19 locations still lack coordinates. They will need to be seek out coords manually.
stillMissing <- loc_noCoords %>%
  filter(is.na(lat))

# Spatial data obtained from eBird My Locations page, manually
missingXY_vec <- c("-40.430443603861484, -71.52732714595885",
                   "21.962500388966415, -80.06262240958718",
                   "37.01274054205935, -76.45330601760207",
                   "-34.40817439312428, -58.58968011287809",
                   "38.96130967755057, -78.73640236441761", #5  George Washington 
                   "36.89192374233853, -76.44309073294882",
                   "-25.599437557304018, -54.56900095919036",
                   "32.1168246, -110.478799",
                   "31.8657879, -109.4118481",
                   "31.8610354, -109.3382328",  #10
                   "31.970572, -109.3321154",
                   "18.373368, -68.815373",
                   "18.70751, -68.44678",
                   "-33.4984608, -58.7883568",
                   "-23.7007266, -65.6840385",    # 15 Cuesta de Lipan
                   "-34.5230615, -58.4680527",  
                   "42.4587784, -73.3565011",
                   "37.0455199, -76.4641169",   
                   "-34.9688638, -58.5851879"   # 19 Estancia Villa Maria
   
                                   )
stillMissing$extractedCoords <- missingXY_vec

# Apply same str_split approach as above
coords_split <- str_split(stillMissing$extractedCoords, ",")

for (i in 1:nrow(stillMissing)) {
    stillMissing$lat[i] <- as.numeric(coords_split[[i]][1])
    stillMissing$long[i] <- as.numeric(coords_split[[i]][2])
}

# Join all coords together in singl df
loc1 <- locations %>%
  filter(!LocID %in% loc_noCoords$LocID)

loc2 <- loc_noCoords %>%
  filter(!is.na(lat)) %>%
  rbind(stillMissing) %>%
  select(LocID, lat, long)

loc_coords <- rbind(loc1, loc2)

# Join coords to life listd df
lifelist <- lifelist %>%
  left_join(loc_coords, by = "LocID")
  

```

## Collect Weather Data

Weather data will be incorporated into the 'Checklist Table'.

### API Wrapper & Other Functions

`rebird` currently has no wrapper for accessing specific checklist information. This function accesses a checklist based on SubID field from life list, then extracts the weather

```{r `get Checklist wrapper`}
library(httr)
library(jsonlite)

api_token <- "jrel4sdsnpqv"

## -- Custom func to get checklist info using eBird api
getChecklist <- function(subId) {
    url <- paste0("https://api.ebird.org/v2/product/checklist/view/", subId)
    response <- httr::GET(url, httr::add_headers(`X-eBirdApiToken` = api_token))
    if (httr::status_code(response) == 200) {
        data <- jsonlite::fromJSON(httr::content(response, "text", encoding = "UTF-8"))
        return(data)
    } else {
        stop("Failed to fetch data: ", httr::status_code(response))
    }
}

```

```{r `FUNC getWeather`}
## ------- Custom func to get weather information given an eBird checklist as input
getWeather <- function(checklist) {
  locid <- checklist$locId
  coords.df <- lifelist %>%
    filter(LocID == locid)

  lat <- as.vector(unlist(coords.df[1, "lat"]))
  long <- as.vector(unlist(coords.df[1, "long"]))
  
  obs_datetime <- checklist$obsDt
  obs_POSIXct <- as.POSIXct(obs_datetime)
  
  split_datetime <- strsplit(obs_datetime, " ")
  obsDate <- unlist(split_datetime)[1]
  
  # Open-Meteo API to get historical weather records
  weatherInfo <- openmeteo::weather_history(location = c(lat, long), 
                                            start = obsDate, 
                                            end = obsDate, 
                                            hourly = c("temperature_2m", "windspeed_10m", "cloudcover", "precipitation")
                                            )
  
  weatherInfo$datetime_char <- as.character(weatherInfo$datetime)
  
  # Round the checklist time to nearest hour to be able to match with a datetime from the hourly weather output
  rounded_obsTime <- as.character(round(obs_POSIXct, units = "hours"))
  
 weatherInfo <- weatherInfo %>%
    filter(datetime_char == rounded_obsTime) %>%
    select(-datetime, -datetime_char)
  
 return(weatherInfo)
}
  
```

```{r `pull in weather data`}
# Create df to hold weather data with unique identifier
weather.df <- data.frame(checklistID = unique(lifelist$SubID),
                         hourly_temperature_2m = NA,
                         hourly_windspeed_10m = NA,
                         hourly_cloudcover = NA,
                         hourly_precipitation = NA)


# Utilize custom functions in for loop to access weather data for each checklist
for (i in seq_along(unique(lifelist$SubID))) {
  subID <- unique(lifelist$SubID)[i]
  checklist <- getChecklist(subID)
  weather <- tryCatch(getWeather(checklist),
                      error = function(e) {
                        cat("Error in iteration:", i, "\n checklist:", subID)
                      }
  )
  
  weather.df$hourly_temperature_2m[i] <- weather$hourly_temperature_2m
  weather.df$hourly_windspeed_10m[i] <- weather$hourly_windspeed_10m
  weather.df$hourly_cloudcover[i] <- weather$hourly_cloudcover
  weather.df$hourly_precipitation[i] <- weather$hourly_precipitation
}
  
```

## Biome & Subbiome for Obs. Locations

ArcGIS has an excellent biomes and ecoregions layer (2017). Exported as shapefile to bring into R.
(Initial vector layer downloaded from journal was inadequate for the task -- inaccurate drawn boundaries at small scale and many birds were not captured in the spatial join)

Using a straightforward spatial join, I determined the biome and subbiome within which each observation location falls. This information will be used in the 'Location Table' of the database.

```{r}
# Read in biome vectors and covert to sf object
shp <- st_read("biomes_ecoregions/biomes.shp")
biomes_sf <- st_as_sf(shp)

# Convert life list to sf object
lifers_sf <- st_as_sf(lifelist, coords = c("long", "lat"), crs = 4326)

# Intersect
lifelist_biomes <- st_intersection(lifers_sf, biomes_sf)

# Still some points not captured in intersection (70 obs total)
## This process took forever (stopped it after 10 min) -- much more efficient to export lifers as shp and run the join in ArcGIS Pro
lifers_biomes <- st_is_within_distance(lifers_sf, biomes_sf, dist = 2000)

```



The below chunk shows my initial attempt to join the life list points to the biome vectors, and how to resolve the initital error I encountered. This couldn't overcome, however, the low precision boundaries and loss of points during the intersection.

```{r `dealing with 'Loop 0' error` eval = FALSE}
shp <- st_read("globalBiomes/biomes_world.shp")
biomes_sf <- st_as_sf(shp)

lifers_sf <- st_as_sf(lifelist, coords = c("long", "lat"), crs = 4326)


## Initital attempt at intersection returned
    ### Error in wk_handle.wk_wkb(wkb, s2_geography_writer(oriented = oriented,  : 
    ### Loop 0 is not valid: Edge 172 crosses edge 174
## "The only remedy is to turn off spherical geometry, rebuild the geometry with st_make_valid() as planar geometry, then crop as planar geometry, even when the geometries are really spherical, and the bounding box should be curvilinear, not rectangular. See: https://r-spatial.org/r/2020/06/17/s2.html and #1771." from github

sf_use_s2(FALSE)
biomes_valid <- st_make_valid(biomes_sf)
biomes_planar <- st_crop(biomes_valid, xmin = -180, ymin = -90, xmax = 0, ymax = 90)  # made bbox western hemisphere only, given my travels

lifelist_biomes <- st_intersection(lifers_sf, biomes_planar)

x <- lifelist_biomes$ObsID

indices_failedIntersect <- which(!lifelist$ObsID %in% x)

y <- lifelist %>%
  filter(ObsID %in% indices_failedIntersect)

y # <-- 102 points are being lost during the intersection operation. Not clear why.

```
